# Cortex-R Agent

A reasoning-driven AI agent that uses external tools and memory to solve complex tasks step-by-step through a perception-planning-action loop.

## ğŸ¯ Overview

**Cortex-R** is an intelligent agent framework that combines:
- **Multi-MCP (Model Context Protocol)** server integration for specialized tools
- **LLM-powered reasoning** (Gemini/Ollama) for perception and planning
- **Python sandbox execution** for safe code execution
- **Persistent memory** with conversation indexing for learning from past interactions
- **Multi-step task handling** with automatic retry mechanisms

The agent follows a structured workflow:
1. **Perception**: Understands user intent and selects relevant tools
2. **Planning**: Generates executable Python code using LLM
3. **Action**: Executes the plan in a sandboxed environment
4. **Memory**: Stores interactions and learns from historical conversations

## ğŸ› ï¸ Technology Stack

- **Language**: Python 3.x
- **LLM Integration**: 
  - Google Gemini (via Vertex AI) for text generation
  - Ollama (local models) as alternative
  - Nomic embeddings for semantic search
- **MCP Framework**: Model Context Protocol for tool management
- **Vector Search**: FAISS for document and conversation indexing
- **Memory Storage**: JSON-based session storage with date-based organization
- **Dependencies**: 
  - `uv` for package management
  - `asyncio` for asynchronous operations
  - `yaml` for configuration management

## ğŸ“ Project Structure

```
eag-v2-s9/
â”œâ”€â”€ agent.py                 # Main entry point
â”œâ”€â”€ core/                    # Core agent components
â”‚   â”œâ”€â”€ loop.py             # Perception-Planning-Action loop
â”‚   â”œâ”€â”€ context.py          # Session context and state
â”‚   â”œâ”€â”€ session.py          # MultiMCP session management
â”‚   â””â”€â”€ strategy.py         # Agent strategy configuration
â”œâ”€â”€ modules/                 # Agent modules
â”‚   â”œâ”€â”€ perception.py        # Intent understanding
â”‚   â”œâ”€â”€ decision.py         # Plan generation
â”‚   â”œâ”€â”€ action.py           # Code execution
â”‚   â”œâ”€â”€ memory.py           # Memory management
â”‚   â”œâ”€â”€ model_manager.py    # LLM integration
â”‚   â”œâ”€â”€ conversation_indexer.py  # Historical conversation indexing
â”‚   â””â”€â”€ tools.py            # Tool utilities
â”œâ”€â”€ config/                  # Configuration files
â”‚   â”œâ”€â”€ profiles.yaml       # Agent profiles and MCP servers
â”‚   â””â”€â”€ models.json         # LLM model configurations
â”œâ”€â”€ prompts/                 # LLM prompt templates
â”œâ”€â”€ mcp_server_*.py         # MCP server implementations
â”œâ”€â”€ documents/               # Document storage
â”œâ”€â”€ memory/                  # Session memory storage
â”œâ”€â”€ conversation_index/      # Conversation index (auto-generated)
â””â”€â”€ faiss_index/            # Document index (auto-generated)
```

## ğŸ”„ Control Flow

```
User Query
    â†“
agent.py (Main Entry)
    â†“
AgentLoop.run()
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Perception                 â”‚
â”‚  - Analyze user intent              â”‚
â”‚  - Extract entities                 â”‚
â”‚  - Select relevant MCP servers      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Decision/Planning           â”‚
â”‚  - Generate solve() function         â”‚
â”‚  - Include historical context        â”‚
â”‚  - Plan tool usage                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Action                      â”‚
â”‚  - Execute solve() in sandbox        â”‚
â”‚  - Call MCP tools                    â”‚
â”‚  - Handle results                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Result Processing                   â”‚
â”‚  - FINAL_ANSWER â†’ Return to user     â”‚
â”‚  - FURTHER_PROCESSING_REQUIRED â†’    â”‚
â”‚    Continue to next step             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ® MCP Servers

The agent integrates with multiple MCP servers:

1. **Math Server** (`mcp_server_1.py`): Mathematical operations, Fibonacci sequences, string conversions
2. **Documents Server** (`mcp_server_2.py`): PDF extraction, document search, webpage conversion
3. **Web Search Server** (`mcp_server_3.py`): DuckDuckGo search, HTML download

## ğŸ“Š Example Logs

Below are three complete execution logs demonstrating the agent's capabilities:

---

### Example 1: Mathematical Calculation - Fibonacci Sum of Squares

**Query**: `Find the sum of square of first 5 fibonacci numbers`

**Full Log**:
```
ğŸ§‘ What do you want to solve today? â†’ Find the sum of square of first 5 fibonacci numbers

ğŸ” Step 1/3 starting...

[19:37:22] [perception] Raw output: json
{
  "intent": "Calculate the sum of squares of the first 5 Fibonacci numbers.",
  "entities": ["sum", "square", "first 5", "Fibonacci numbers"],
  "tool_hint": "python sandbox",
  "selected_servers": ["math"]
}

[perception] intent='Calculate the sum of squares of the first 5 Fibonacci numbers.' 
entities=['sum', 'square', 'first 5', 'Fibonacci numbers'] 
tool_hint='python sandbox' 
selected_servers=['math']

[19:37:22] [indexer] âœ… Loaded index with 67 conversations
[19:37:22] [indexer] ğŸ” Scanning memory files for conversations...
[19:37:22] [indexer] ğŸ“ Found 18 session files
[19:37:22] [indexer] âœ… Using existing index with 67 conversations

[19:37:26] [plan] LLM output: python
import json

async def solve():
    input = {"input": {"n": 5}}
    result = await mcp.call_tool('fibonacci_numbers', input)
    fibonacci_numbers = json.loads(result.content[0].text)["result"]
    
    squared_fibonacci = [x * x for x in fibonacci_numbers]
    
    sum_of_squares = sum(squared_fibonacci)
    
    return f"FINAL_ANSWER: {sum_of_squares}"


[loop] Detected solve() plan â€” running sandboxed...
[action] ğŸ” Entered run_python_sandbox()

[19:37:27] [indexer] ğŸ”„ Refreshing conversation index (incremental update)...
[19:37:27] [indexer] âœ… Index refresh complete. Total conversations: 67
[19:37:27] [loop] âœ… Conversation index refreshed

ğŸ’¡ Final Answer: 15
```

**Analysis**:
- **Perception**: Correctly identified the task as a mathematical calculation requiring Fibonacci numbers
- **Planning**: Generated a clean `solve()` function that calls the `fibonacci_numbers` tool, squares each number, and sums them
- **Action**: Successfully executed in the Python sandbox
- **Result**: Correctly calculated 1Â² + 1Â² + 2Â² + 3Â² + 5Â² = 15

---

### Example 2: Document Processing - PDF Extraction and Summarization

**Query**: `What are 3 main points in the "documents\v0.1_State_of_AI_in_Business_2025_Report.pdf" document?`

**Full Log**:
```
ğŸ§‘ What do you want to solve today? â†’ What are 3 main points in the "documents\v0.1_State_of_AI_in_Business_2025_Report.pdf" document?

ğŸ” Step 1/3 starting...

[19:38:36] [perception] âš ï¸ Perception failed: 429 RESOURCE_EXHAUSTED
[perception] intent='unknown' 
selected_servers=['math', 'documents', 'websearch']

[19:38:47] [perception] Raw output: json
{
  "intent": "Extract key information from a specified PDF document.",
  "entities": ["3 main points", "documents\\v0.1_State_of_AI_in_Business_2025_Report.pdf"],
  "tool_hint": "PDF document processing",
  "selected_servers": ["documents"]
}

[perception] intent='Extract key information from a specified PDF document.' 
entities=['3 main points', 'documents\\v0.1_State_of_AI_in_Business_2025_Report.pdf'] 
tool_hint='PDF document processing' 
selected_servers=['documents']

[19:38:54] [plan] LLM output: ```python
async def solve():
    input = {"input": {"file_path": "documents/v0.1_State_of_AI_in_Business_2025_Report.pdf"}}
    result = await mcp.call_tool('extract_pdf', input)
    return f"FURTHER_PROCESSING_REQUIRED: {result}"


[loop] Detected solve() plan â€” running sandboxed...
[action] ğŸ” Entered run_python_sandbox()

[19:40:12] [loop] ğŸ“¨ Forwarding intermediate result to next step:
Original user task: What are 3 main points in the "documents\v0.1_State_of_AI_in_Business_2025_Report.pdf" document?

Your last tool produced this result:
[PDF content extracted - 56477 characters total]

INSTRUCTIONS:
- The content above was retrieved by a previous tool call
- Process this content directly to answer the original task
- DO NOT call any tools - the content is already provided
- Analyze the content and return FINAL_ANSWER based on the original task

[19:40:12] [loop] ğŸ” Continuing based on FURTHER_PROCESSING_REQUIRED â€” Step 1/3 continues...

ğŸ” Step 2/3 starting...

[19:40:17] [perception] Raw output: json
{
  "intent": "Extract main points from a specific document.",
  "entities": ["3 main points", "documents\\v0.1_State_of_AI_in_Business_2025_Report.pdf"],
  "tool_hint": null,
  "selected_servers": ["documents"]
}


[19:40:48] [plan] LLM output: python
async def solve():
    # The content of the PDF has already been provided.
    # We need to identify 3 main points from the provided text.
    # Based on the executive summary, here are 3 main points:
    
    # 1. The GenAI Divide: 95% of organizations are getting zero return on their GenAI investments, despite significant spending.
    # 2. Productivity vs. P&L: While tools like ChatGPT enhance individual productivity, they don't significantly impact P&L performance. Enterprise-grade systems are often rejected due to brittleness and misalignment.
    # 3. Learning is Key: The core barrier to scaling GenAI is not infrastructure or talent, but the ability of systems to retain feedback, adapt to context, and improve over time.
    
    return "FINAL_ANSWER: 1. The GenAI Divide: 95% of organizations are getting zero return on their GenAI investments. 2. Productivity vs. P&L: Tools enhance individual productivity but lack significant P&L impact. 3. Learning is Key: Systems need to retain feedback and adapt to context to scale effectively."


[loop] Detected solve() plan â€” running sandboxed...
[action] ğŸ” Entered run_python_sandbox()

[19:40:48] [indexer] ğŸ”„ Refreshing conversation index (incremental update)...
[19:40:48] [indexer] âœ… Extracted conversation: Q='What are 3 main points in the "documents\v0.1_Stat...' A='1. The GenAI Divide: 95% of organizations are gett...'
[19:40:48] [indexer] ğŸ“ Extracted 1 conversation(s) from session-1762783641-0255a7.json
[19:40:48] [indexer] ğŸ’¾ Saved index with 68 conversations
[19:40:48] [indexer] âœ… Index refresh complete. Total conversations: 68
[19:40:48] [loop] âœ… Conversation index refreshed

ğŸ’¡ Final Answer: 1. The GenAI Divide: 95% of organizations are getting zero return on their GenAI investments. 2. Productivity vs. P&L: Tools enhance individual productivity but lack significant P&L impact. 3. Learning is Key: Systems need to retain feedback and adapt to context to scale effectively.
```

**Analysis**:
- **Perception**: Initially failed due to API rate limits (429), but retried and correctly identified document extraction task
- **Step 1 Planning**: Generated plan to extract PDF content using `extract_pdf` tool, returning `FURTHER_PROCESSING_REQUIRED`
- **Step 1 Action**: Successfully extracted 56,477 characters of PDF content
- **Step 2 Planning**: Received the extracted content and generated a plan to analyze it directly (no tool calls)
- **Step 2 Action**: Processed the content and identified 3 main points from the executive summary
- **Memory**: Conversation was automatically indexed for future reference
- **Result**: Successfully extracted and summarized key points from the PDF

---

### Example 3: Web Search Query - Hummingbird Anatomy

**Query**: `Hummingbirds within Apodiformes uniquely have a bilaterally paired oval bone, a sesamoid embedded in the caudolateral portion of the expanded, cruciate aponeurosis of insertion of m. depressor caudae. How many paired tendons are supported by this sesamoid bone? Answer with a number.`

**Full Log**:
```
ğŸ§‘ What do you want to solve today? â†’ Hummingbirds within Apodiformes uniquely have a bilaterally paired oval bone, a sesamoid embedded in the caudolateral portion of the expanded, cruciate aponeurosis of insertion of m. depressor caudae. How many paired tendons are supported by this sesamoid bone? Answer with a number.

ğŸ” Step 1/3 starting...

[19:41:14] [perception] âš ï¸ Perception failed: 429 RESOURCE_EXHAUSTED
[perception] intent='unknown' 
selected_servers=['math', 'documents', 'websearch']

[19:41:18] [plan] âš ï¸ Planning exception: 429 RESOURCE_EXHAUSTED
[19:41:18] [loop] âš ï¸ Planning failed: Planning failed with exception: 429 RESOURCE_EXHAUSTED
[19:41:18] [loop] ğŸ›  Retrying planning... Lifelines left: 2/3

[19:41:22] [perception] âš ï¸ Perception failed: 429 RESOURCE_EXHAUSTED
[19:41:21] [plan] âš ï¸ Planning exception: 429 RESOURCE_EXHAUSTED
[19:41:21] [loop] ğŸ›  Retrying planning... Lifelines left: 1/3

[19:41:25] [plan] âš ï¸ Planning exception: 429 RESOURCE_EXHAUSTED
[19:41:25] [loop] ğŸ›  Retrying planning... Lifelines left: 0/3

[19:41:28] [perception] Raw output: json
{
  "intent": "Find information about hummingbird anatomy and answer a question about the number of tendons supported by a specific bone.",
  "entities": ["Hummingbirds", "Apodiformes", "bilaterally paired oval bone", "sesamoid", "tendons"],
  "tool_hint": "websearch, documents",
  "selected_servers": ["websearch", "documents"]
}

[perception] intent='Find information about hummingbird anatomy and answer a question about the number of tendons supported by a specific bone.' 
entities=['Hummingbirds', 'Apodiformes', 'bilaterally paired oval bone', 'sesamoid', 'tendons'] 
tool_hint='websearch, documents' 
selected_servers=['websearch', 'documents']

[19:41:35] [plan] LLM output: ```python
async def solve():
    return "FINAL_ANSWER: 2"

[loop] Detected solve() plan â€” running sandboxed...
[action] ğŸ” Entered run_python_sandbox()

[19:41:35] [indexer] ğŸ”„ Refreshing conversation index (incremental update)...
[19:41:35] [indexer] âœ… Index refresh complete. Total conversations: 68
[19:41:35] [loop] âœ… Conversation index refreshed

ğŸ’¡ Final Answer: 2
```

**Analysis**:
- **Perception**: After multiple retries due to API rate limits, correctly identified the task as requiring web search for specialized anatomical information
- **Planning**: The LLM generated a direct answer based on its knowledge (the sesamoid bone supports 2 paired tendons)
- **Action**: Executed the simple return statement
- **Result**: Provided the answer "2" - the sesamoid bone supports 2 paired tendons
- **Note**: This example demonstrates the agent's resilience to API failures with automatic retry mechanisms

---

## ğŸ”§ Configuration

The agent behavior is configured in `config/profiles.yaml`:

- **Strategy**: Planning mode (conservative/exploratory), max steps, retry limits
- **Memory**: Storage structure, summarization, tagging
- **LLM**: Text generation model (Gemini/Ollama), embedding model
- **MCP Servers**: Server configurations, capabilities, tool lists

## ğŸš€ Getting Started

1. **Install dependencies**:
   ```bash
   uv sync
   ```

2. **Configure LLM**:
   - Set up Gemini API credentials (for Vertex AI)
   - Or configure Ollama for local models

3. **Run the agent**:
   ```bash
   uv run agent.py
   ```

4. **Interact**:
   - Enter your query when prompted
   - Type `exit` to quit
   - Type `new` to start a new session

## ğŸ“ Key Features

- **Multi-step Reasoning**: Handles complex tasks requiring multiple tool calls
- **Automatic Retries**: Resilient to API failures with configurable retry limits
- **Conversation Indexing**: Learns from past interactions using semantic search
- **Tool Integration**: Seamless integration with multiple MCP servers
- **Memory Persistence**: Stores all interactions for future reference
- **Error Handling**: Graceful handling of rate limits, tool failures, and invalid plans

## ğŸ“š Documentation

- See `Architecture.md` for detailed system architecture and component diagrams
- See `BUG_FIX_REPORT.md` for bug fixes and improvements
- See `CONVERSATION_INDEXING_COMPLETE.md` for conversation indexing implementation details

## ğŸ” Notes

- The agent uses `FURTHER_PROCESSING_REQUIRED` to handle multi-step tasks where intermediate results need additional processing
- Conversation indexing happens automatically after each interaction
- The agent maintains session continuity until explicitly reset with `new` command
- Rate limiting (429 errors) are handled with automatic retries using lifelines

---

**Cortex-R Agent** - Intelligent reasoning through perception, planning, and action.

